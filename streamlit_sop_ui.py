#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Streamlit UI for SOP Document Processing
æ™ºèƒ½SOPæ–‡æ¡£å¤„ç†ç³»ç»Ÿçš„Webç•Œé¢
"""

import streamlit as st
import os
import tempfile
import zipfile
from pathlib import Path
import pandas as pd
from typing import List, Tuple
import time
import shutil
from process_sop_with_images import process_sop_document_with_images

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="SOP Navigator - æ™ºèƒ½æ–‡æ¡£å¤„ç†ç³»ç»Ÿ",
    page_icon="ğŸ“š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# è‡ªå®šä¹‰CSSæ ·å¼
st.markdown("""
<style>
    .main-header {
        background: linear-gradient(90deg, #1e3c72 0%, #2a5298 100%);
        color: white;
        padding: 1rem;
        border-radius: 10px;
        text-align: center;
        margin-bottom: 2rem;
    }
    .upload-section {
        border: 2px dashed #4CAF50;
        border-radius: 10px;
        padding: 2rem;
        text-align: center;
        background-color: #f8f9fa;
        margin: 1rem 0;
    }
    .success-box {
        background-color: #d4edda;
        border: 1px solid #c3e6cb;
        color: #155724;
        padding: 1rem;
        border-radius: 5px;
        margin: 1rem 0;
    }
    .error-box {
        background-color: #f8d7da;
        border: 1px solid #f5c6cb;
        color: #721c24;
        padding: 1rem;
        border-radius: 5px;
        margin: 1rem 0;
    }
    .info-box {
        background-color: #d1ecf1;
        border: 1px solid #bee5eb;
        color: #0c5460;
        padding: 1rem;
        border-radius: 5px;
        margin: 1rem 0;
    }
</style>
""", unsafe_allow_html=True)

def init_session_state():
    """åˆå§‹åŒ–ä¼šè¯çŠ¶æ€"""
    if 'processed_files' not in st.session_state:
        st.session_state.processed_files = []
    if 'processing_complete' not in st.session_state:
        st.session_state.processing_complete = False
    if 'output_dir' not in st.session_state:
        st.session_state.output_dir = None

def create_output_directories() -> Tuple[Path, Path]:
    """åˆ›å»ºè¾“å‡ºç›®å½•"""
    current_dir = Path(__file__).parent
    output_dir = current_dir / "streamlit_output"
    images_dir = current_dir / "sop_images"
    
    output_dir.mkdir(exist_ok=True)
    images_dir.mkdir(exist_ok=True)
    
    return output_dir, images_dir

def is_word_document(filename: str) -> bool:
    """æ£€æŸ¥æ–‡ä»¶æ˜¯å¦ä¸ºWordæ–‡æ¡£"""
    return filename.lower().endswith(('.docx', '.doc'))

def create_images_zip(images_dir: Path) -> bytes:
    """åˆ›å»ºåŒ…å«æ‰€æœ‰å›¾ç‰‡çš„ZIPæ–‡ä»¶"""
    import io
    
    zip_buffer = io.BytesIO()
    
    # è·å–æ‰€æœ‰å›¾ç‰‡æ–‡ä»¶
    image_files = list(images_dir.glob("*.png")) + list(images_dir.glob("*.jpg")) + list(images_dir.glob("*.jpeg"))
    
    if not image_files:
        return b""
    
    with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zip_file:
        for img_file in sorted(image_files):
            # ä½¿ç”¨ç›¸å¯¹è·¯å¾„ä½œä¸ºZIPå†…çš„æ–‡ä»¶å
            zip_file.write(img_file, img_file.name)
    
    zip_buffer.seek(0)
    return zip_buffer.getvalue()

def save_uploaded_file(uploaded_file, temp_dir: Path) -> Path:
    """ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶åˆ°ä¸´æ—¶ç›®å½•"""
    file_path = temp_dir / uploaded_file.name
    with open(file_path, "wb") as f:
        f.write(uploaded_file.getbuffer())
    return file_path

def extract_zip_files(zip_file, temp_dir: Path) -> List[Path]:
    """ä»ZIPæ–‡ä»¶ä¸­æå–Wordæ–‡æ¡£"""
    word_files = []
    
    with zipfile.ZipFile(zip_file, 'r') as zip_ref:
        zip_ref.extractall(temp_dir)
        
        # é€’å½’æŸ¥æ‰¾æ‰€æœ‰Wordæ–‡æ¡£
        for root, dirs, files in os.walk(temp_dir):
            for file in files:
                if is_word_document(file):
                    word_files.append(Path(root) / file)
    
    return word_files

def process_single_document(doc_path: Path, output_dir: Path) -> Tuple[bool, str]:
    """å¤„ç†å•ä¸ªæ–‡æ¡£"""
    try:
        result = process_sop_document_with_images(str(doc_path), str(output_dir))
        if result:
            return True, f"âœ… æˆåŠŸå¤„ç†: {doc_path.name}"
        else:
            return False, f"âŒ å¤„ç†å¤±è´¥: {doc_path.name}"
    except Exception as e:
        return False, f"âŒ å¤„ç†å‡ºé”™: {doc_path.name} - {str(e)}"

def display_results(processed_files: List[dict], output_dir: Path, images_dir: Path, context: str = "main"):
    """æ˜¾ç¤ºå¤„ç†ç»“æœ"""
    # å¦‚æœæ˜¯å†å²è®°å½•ä¸”æ²¡æœ‰processed_filesï¼Œæ˜¾ç¤ºæ‰€æœ‰å¯ç”¨æ–‡ä»¶
    show_all_files = (context == "history" and not processed_files)
    
    if not processed_files and not show_all_files:
        return
    
    success_count = sum(1 for f in processed_files if f['success']) if processed_files else 0
    error_count = len(processed_files) - success_count if processed_files else 0
    
    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    if not show_all_files:
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("æ€»æ–‡æ¡£æ•°", len(processed_files))
        with col2:
            st.metric("æˆåŠŸå¤„ç†", success_count, delta=success_count)
        with col3:
            st.metric("å¤„ç†å¤±è´¥", error_count, delta=-error_count if error_count > 0 else 0)
        
        # æ˜¾ç¤ºè¯¦ç»†ç»“æœ
        st.subheader("ğŸ“‹ å¤„ç†è¯¦æƒ…")
        for file_info in processed_files:
            if file_info['success']:
                st.success(file_info['message'])
            else:
                st.error(file_info['message'])
    
    # æ˜¾ç¤ºç”Ÿæˆçš„æ–‡ä»¶
    if show_all_files:
        # å†å²è®°å½•æ¨¡å¼ï¼šæ˜¾ç¤ºæ‰€æœ‰æ–‡ä»¶
        csv_files = list(output_dir.glob("*_processed_with_images.csv"))
        image_files = list(images_dir.glob("*.png")) + list(images_dir.glob("*.jpg")) + list(images_dir.glob("*.jpeg"))
    else:
        # å½“å‰ä¼šè¯æ¨¡å¼ï¼šåªæ˜¾ç¤ºå½“å‰å¤„ç†ä¼šè¯ç›¸å…³çš„æ–‡ä»¶
        # ä»processed_filesè·å–æˆåŠŸå¤„ç†çš„æ–‡ä»¶åï¼ˆä¸å«æ‰©å±•åï¼‰
        processed_doc_names = []
        for file_info in processed_files:
            if file_info['success']:
                # ç§»é™¤æ–‡ä»¶æ‰©å±•åï¼Œè·å–åŸºç¡€åç§°
                base_name = file_info['filename'].replace('.docx', '').replace('.doc', '')
                processed_doc_names.append(base_name)
        
        # åªæ˜¾ç¤ºä¸å½“å‰å¤„ç†ä¼šè¯ç›¸å…³çš„CSVæ–‡ä»¶
        all_csv_files = list(output_dir.glob("*_processed_with_images.csv"))
        csv_files = []
        for csv_file in all_csv_files:
            csv_base_name = csv_file.name.replace('_processed_with_images.csv', '')
            if csv_base_name in processed_doc_names:
                csv_files.append(csv_file)
        
        # åªæ˜¾ç¤ºä¸å½“å‰å¤„ç†ä¼šè¯ç›¸å…³çš„å›¾ç‰‡æ–‡ä»¶
        all_image_files = list(images_dir.glob("*.png")) + list(images_dir.glob("*.jpg")) + list(images_dir.glob("*.jpeg"))
        image_files = []
        for img_file in all_image_files:
            # æ£€æŸ¥å›¾ç‰‡æ–‡ä»¶åæ˜¯å¦åŒ…å«å½“å‰å¤„ç†çš„æ–‡æ¡£å
            for doc_name in processed_doc_names:
                if doc_name in img_file.name:
                    image_files.append(img_file)
                    break
    
    if csv_files:
        st.subheader(f"ğŸ“„ ç”Ÿæˆçš„CSVæ–‡ä»¶ ({len(csv_files)} ä¸ª)")
        
        # æ˜¾ç¤ºCSVæ–‡ä»¶è·¯å¾„å’Œç»Ÿè®¡ä¿¡æ¯
        col_csv1, col_csv2 = st.columns(2)
        with col_csv1:
            st.info(f"ğŸ“ CSVä¿å­˜è·¯å¾„: `{output_dir}`")
        with col_csv2:
            total_size = sum(csv_file.stat().st_size for csv_file in csv_files)
            st.info(f"ğŸ“Š æ€»å¤§å°: {total_size / 1024:.1f} KB")
        
        # æ˜¾ç¤ºæ¯ä¸ªCSVæ–‡ä»¶
        for i, csv_file in enumerate(sorted(csv_files)):
            col_file, col_btn = st.columns([2, 1])
            
            with col_file:
                file_size = csv_file.stat().st_size / 1024  # KB
                st.write(f"ğŸ“„ {csv_file.name} ({file_size:.1f} KB)")
            
            with col_btn:
                # æä¾›ä¸‹è½½æŒ‰é’® - ä½¿ç”¨ä¸Šä¸‹æ–‡å’Œç´¢å¼•åˆ›å»ºå”¯ä¸€key
                with open(csv_file, 'rb') as f:
                    st.download_button(
                        label="â¬‡ï¸ ä¸‹è½½",
                        data=f.read(),
                        file_name=csv_file.name,
                        mime="text/csv",
                        key=f"download_csv_{context}_{i}_{csv_file.stem}"
                    )
    
    if image_files:
        # åˆ›å»ºæ ‡é¢˜å’Œä¸‹è½½æŒ‰é’®çš„åˆ—å¸ƒå±€
        col1, col2 = st.columns([3, 1])
        with col1:
            st.subheader(f"ğŸ–¼ï¸ æå–çš„å›¾ç‰‡æ–‡ä»¶ ({len(image_files)} ä¸ª)")
        with col2:
            # åˆ›å»ºZIPæ–‡ä»¶å¹¶æä¾›ä¸‹è½½
            zip_data = create_images_zip(images_dir)
            if zip_data:
                st.download_button(
                    label="ğŸ“¦ ä¸‹è½½æ‰€æœ‰å›¾ç‰‡ (ZIP)",
                    data=zip_data,
                    file_name=f"sop_images_{time.strftime('%Y%m%d_%H%M%S')}.zip",
                    mime="application/zip",
                    key=f"download_images_zip_{context}"
                )
        
        # æ˜¾ç¤ºå›¾ç‰‡è·¯å¾„å’Œç»Ÿè®¡ä¿¡æ¯
        col_info1, col_info2 = st.columns(2)
        with col_info1:
            st.info(f"ğŸ“ å›¾ç‰‡ä¿å­˜è·¯å¾„: `{images_dir}`")
        with col_info2:
            png_count = len([f for f in image_files if f.suffix.lower() == '.png'])
            jpg_count = len([f for f in image_files if f.suffix.lower() in ['.jpg', '.jpeg']])
            st.info(f"ğŸ“Š æ ¼å¼ç»Ÿè®¡: PNG ({png_count}), JPG ({jpg_count})")
        
        # å›¾ç‰‡é¢„è§ˆï¼ˆæ˜¾ç¤ºå‰å‡ å¼ ï¼‰
        preview_count = min(6, len(image_files))
        cols = st.columns(3)
        for i, img_file in enumerate(sorted(image_files)[:preview_count]):
            with cols[i % 3]:
                try:
                    st.image(str(img_file), caption=img_file.name, width=200)
                except Exception as e:
                    st.write(f"ğŸ–¼ï¸ {img_file.name}")
        
        if len(image_files) > preview_count:
            st.write(f"... è¿˜æœ‰ {len(image_files) - preview_count} å¼ å›¾ç‰‡")

def main():
    """ä¸»å‡½æ•°"""
    init_session_state()
    
    # é¡µé¢æ ‡é¢˜
    st.markdown("""
    <div class="main-header">
        <h1>ğŸ“š SOP Navigator</h1>
        <h3>æ™ºèƒ½SOPæ–‡æ¡£å¤„ç†ç³»ç»Ÿ</h3>
        <p>å°†Wordæ ¼å¼çš„SOPæ–‡æ¡£è½¬æ¢ä¸ºç»“æ„åŒ–CSVæ•°æ®ï¼Œæ”¯æŒå›¾ç‰‡æå–å’Œè¡¨æ ¼å¤„ç†</p>
    </div>
    """, unsafe_allow_html=True)
    
    # ä¾§è¾¹æ è¯´æ˜
    with st.sidebar:
        st.header("ğŸ“– ä½¿ç”¨è¯´æ˜")
        st.markdown("""
        ### æ”¯æŒçš„æ–‡ä»¶æ ¼å¼ï¼š
        - Wordæ–‡æ¡£ (.docx, .doc)
        - ZIPå‹ç¼©åŒ…ï¼ˆåŒ…å«Wordæ–‡æ¡£ï¼‰
        
        ### å¤„ç†åŠŸèƒ½ï¼š
        - âœ… æ™ºèƒ½æ ‡é¢˜è¯†åˆ«
        - âœ… è¡¨æ ¼è½¬æ¢ä¸å½’å±
        - âœ… å›¾ç‰‡è‡ªåŠ¨æå–
        - âœ… å†…å®¹ç»“æ„åŒ–å¤„ç†
        - âœ… æ‰¹é‡æ–‡æ¡£å¤„ç†
        
        ### è¾“å‡ºç»“æœï¼š
        - ğŸ“„ ç»“æ„åŒ–CSVæ–‡ä»¶ (streamlit_output/)
        - ğŸ–¼ï¸ æå–çš„å›¾ç‰‡æ–‡ä»¶ (sop_images/)
        - ğŸ“¦ å›¾ç‰‡æ‰¹é‡ä¸‹è½½ (ZIPå‹ç¼©åŒ…)
        - ğŸ“Š å¤„ç†ç»Ÿè®¡æŠ¥å‘Š
        
        ### ğŸš¨ å¸¸è§é—®é¢˜è§£å†³ï¼š
        - **403é”™è¯¯**: æ–‡ä»¶è¿‡å¤§æˆ–ç½‘ç»œé—®é¢˜ï¼Œå°è¯•åˆ·æ–°é¡µé¢
        - **ä¸Šä¼ å¤±è´¥**: ç¡®ä¿æ–‡ä»¶æ ¼å¼æ­£ç¡®(.docx/.doc/.zip)
        - **å¤„ç†è¶…æ—¶**: å¤§æ–‡ä»¶éœ€è¦æ›´é•¿æ—¶é—´ï¼Œè¯·è€å¿ƒç­‰å¾…
        """)
        
        st.header("ğŸ”§ ç³»ç»Ÿä¿¡æ¯")
        st.info("åŸºäºPython-docxå’ŒPandasæ„å»º")
        st.success("âœ… å½“å‰é…ç½®: æœ€å¤§æ–‡ä»¶200MB, CORSå·²ç¦ç”¨")
        
        # æ˜¾ç¤ºå½“å‰æ–‡ä»¶çŠ¶æ€
        current_dir = Path(__file__).parent
        output_dir = current_dir / "streamlit_output"
        images_dir = current_dir / "sop_images"
        
        if output_dir.exists():
            existing_csvs = list(output_dir.glob("*_processed_with_images.csv"))
            if existing_csvs:
                total_csv_size = sum(csv.stat().st_size for csv in existing_csvs) / 1024
                st.success(f"ğŸ“„ å·²æœ‰ {len(existing_csvs)} ä¸ªCSVæ–‡ä»¶ ({total_csv_size:.1f}KB)")
            else:
                st.info("ğŸ“„ CSVç›®å½•ä¸ºç©ºï¼Œå¤„ç†æ–‡æ¡£åå°†ç”ŸæˆCSV")
        
        if images_dir.exists():
            existing_images = list(images_dir.glob("*.png")) + list(images_dir.glob("*.jpg")) + list(images_dir.glob("*.jpeg"))
            if existing_images:
                st.success(f"ï¿½ï¸ å·²æœ‰ {len(existing_images)} å¼ æå–çš„å›¾ç‰‡")
            else:
                st.info("ï¿½ï¸ å›¾ç‰‡ç›®å½•ä¸ºç©ºï¼Œå¤„ç†æ–‡æ¡£åå°†æ˜¾ç¤ºå›¾ç‰‡")
    
    # ä¸»è¦å†…å®¹åŒºåŸŸ
    tab1, tab2 = st.tabs(["ğŸ“ æ–‡æ¡£ä¸Šä¼ å¤„ç†", "ğŸ“Š å¤„ç†å†å²"])
    
    with tab1:
        st.markdown("""
        <div class="upload-section">
            <h3>ğŸ“ æ‹–æ‹½ä¸Šä¼ æ–‡æ¡£</h3>
            <p>æ”¯æŒå•ä¸ªæ–‡æ¡£æˆ–æ–‡ä»¶å¤¹ï¼ˆZIPæ ¼å¼ï¼‰ä¸Šä¼ </p>
        </div>
        """, unsafe_allow_html=True)
        
        # æ–‡ä»¶ä¸Šä¼ ç»„ä»¶
        try:
            uploaded_files = st.file_uploader(
                "é€‰æ‹©Wordæ–‡æ¡£æˆ–ZIPæ–‡ä»¶",
                type=['docx', 'doc', 'zip'],
                accept_multiple_files=True,
                help="æ”¯æŒæ‹–æ‹½å¤šä¸ªæ–‡ä»¶æˆ–ZIPå‹ç¼©åŒ…ï¼ˆå•ä¸ªæ–‡ä»¶æœ€å¤§200MBï¼‰"
            )
        except Exception as e:
            st.error(f"æ–‡ä»¶ä¸Šä¼ å‡ºé”™: {str(e)}")
            st.info("ğŸ’¡ æç¤ºï¼šå¦‚æœé‡åˆ°403é”™è¯¯ï¼Œè¯·å°è¯•åˆ·æ–°é¡µé¢æˆ–ä½¿ç”¨è¾ƒå°çš„æ–‡ä»¶")
            uploaded_files = None
        
        if uploaded_files:
            # éªŒè¯æ–‡ä»¶å¤§å°
            max_size = 200 * 1024 * 1024  # 200MB
            valid_files = []
            
            for file in uploaded_files:
                if file.size > max_size:
                    st.error(f"âŒ æ–‡ä»¶ {file.name} å¤ªå¤§ ({file.size / 1024 / 1024:.1f}MB)ï¼Œè¯·ä½¿ç”¨å°äº200MBçš„æ–‡ä»¶")
                else:
                    valid_files.append(file)
            
            if valid_files:
                st.success(f"å·²ä¸Šä¼  {len(valid_files)} ä¸ªæœ‰æ•ˆæ–‡ä»¶")
                
                # æ˜¾ç¤ºä¸Šä¼ çš„æ–‡ä»¶åˆ—è¡¨
                st.subheader("ğŸ“‹ ä¸Šä¼ æ–‡ä»¶åˆ—è¡¨")
                for file in valid_files:
                    file_type = "ZIPå‹ç¼©åŒ…" if file.name.endswith('.zip') else "Wordæ–‡æ¡£"
                    file_size_mb = file.size / 1024 / 1024
                    st.write(f"ğŸ“„ {file.name} ({file_type}, {file_size_mb:.1f}MB)")
                
                uploaded_files = valid_files  # åªå¤„ç†æœ‰æ•ˆæ–‡ä»¶
            else:
                st.warning("æ²¡æœ‰æœ‰æ•ˆçš„æ–‡ä»¶å¯ä»¥å¤„ç†")
                uploaded_files = None
            
            # å¤„ç†æŒ‰é’®
            if st.button("ğŸš€ å¼€å§‹å¤„ç†æ–‡æ¡£", type="primary", use_container_width=True, key="process_documents_btn"):
                output_dir, images_dir = create_output_directories()
                
                with tempfile.TemporaryDirectory() as temp_dir:
                    temp_path = Path(temp_dir)
                    all_word_files = []
                    
                    # å¤„ç†ä¸Šä¼ çš„æ–‡ä»¶
                    progress_bar = st.progress(0)
                    status_text = st.empty()
                    
                    for i, uploaded_file in enumerate(uploaded_files):
                        status_text.text(f"æ­£åœ¨å¤„ç†æ–‡ä»¶ {i+1}/{len(uploaded_files)}: {uploaded_file.name}")
                        
                        if uploaded_file.name.endswith('.zip'):
                            # å¤„ç†ZIPæ–‡ä»¶
                            zip_path = save_uploaded_file(uploaded_file, temp_path)
                            word_files = extract_zip_files(zip_path, temp_path)
                            all_word_files.extend(word_files)
                        else:
                            # å¤„ç†Wordæ–‡æ¡£
                            if is_word_document(uploaded_file.name):
                                word_path = save_uploaded_file(uploaded_file, temp_path)
                                all_word_files.append(word_path)
                        
                        progress_bar.progress((i + 1) / len(uploaded_files) / 2)
                    
                    if not all_word_files:
                        st.error("âŒ æœªæ‰¾åˆ°å¯å¤„ç†çš„Wordæ–‡æ¡£ï¼")
                        return
                    
                    st.info(f"ğŸ“„ æ‰¾åˆ° {len(all_word_files)} ä¸ªWordæ–‡æ¡£ï¼Œå¼€å§‹å¤„ç†...")
                    
                    # å¤„ç†Wordæ–‡æ¡£
                    processed_files = []
                    for i, doc_path in enumerate(all_word_files):
                        status_text.text(f"æ­£åœ¨å¤„ç†æ–‡æ¡£ {i+1}/{len(all_word_files)}: {doc_path.name}")
                        
                        success, message = process_single_document(doc_path, output_dir)
                        processed_files.append({
                            'filename': doc_path.name,
                            'success': success,
                            'message': message
                        })
                        
                        progress_bar.progress(0.5 + (i + 1) / len(all_word_files) / 2)
                    
                    status_text.text("å¤„ç†å®Œæˆï¼")
                    progress_bar.progress(1.0)
                    
                    # ä¿å­˜å¤„ç†ç»“æœåˆ°ä¼šè¯çŠ¶æ€
                    st.session_state.processed_files = processed_files
                    st.session_state.processing_complete = True
                    st.session_state.output_dir = output_dir
                    
                    # æ˜¾ç¤ºç»“æœ
                    st.success("ğŸ‰ æ–‡æ¡£å¤„ç†å®Œæˆï¼")
                    display_results(processed_files, output_dir, images_dir, "processing")
    
    with tab2:
        st.subheader("ğŸ“Š å¤„ç†å†å²")
        
        if st.session_state.processing_complete and st.session_state.processed_files:
            output_dir, images_dir = create_output_directories()
            display_results(st.session_state.processed_files, output_dir, images_dir, "history")
            
            # æ¸…é™¤å†å²æŒ‰é’®
            if st.button("ğŸ—‘ï¸ æ¸…é™¤å¤„ç†å†å²", type="secondary", key="clear_history_btn"):
                st.session_state.processed_files = []
                st.session_state.processing_complete = False
                st.session_state.output_dir = None
                st.rerun()
        else:
            st.info("ğŸ“ æš‚æ— å¤„ç†å†å²è®°å½•ã€‚è¯·å…ˆåœ¨ä¸Šä¼ å¤„ç†é¡µé¢å¤„ç†æ–‡æ¡£ã€‚")
    
    # é¡µè„š
    st.markdown("---")
    st.markdown("""
    <div style="text-align: center; color: #666; padding: 1rem;">
        <p>ğŸ”§ SOP Navigator v1.0 | æ™ºèƒ½SOPæ–‡æ¡£å¤„ç†ç³»ç»Ÿ</p>
        <p>ğŸ’¡ æ”¯æŒWordæ–‡æ¡£æ‰¹é‡å¤„ç†ã€å›¾ç‰‡æå–ã€è¡¨æ ¼è½¬æ¢ç­‰åŠŸèƒ½</p>
    </div>
    """, unsafe_allow_html=True)

if __name__ == "__main__":
    main()